\documentclass[document.tex]{subfiles}

\begin{document}

\section{Введение. Сходимости векторов.}

\subsection{Введение.}

Математическая статистика -- это раздел теории вероятностей, который решает обратные задачи к классическим задачам в теории вероятностей.

Типичная задача в теории вероятностей -- это найти или оценить характеристики случайного эксперимента, зная его природу случайности.

Типичная задача в математической статистике -- по данным результатов случайного эксперимента выяснить природу его случайности.

\begin{example}[Классический пример]
	В городе есть $n$ жителей, $m$ из которых болеют. Считаем, что $n$ дано заранее.
	\begin{itemize}
		\item Задача ТВ: с какой вероятностью при известном $m$ в случайной выборке из $a$ жителей будет $b$ заболевших
		\item Задача МС: известно, что в выборке из $a$ жителей оказалось $b$ заболевших. Как в этом случае можно оценить $m$
	\end{itemize}
\end{example}

\begin{example}[Выборка]
	Предположим, что мы проводим эксперимент. Пусть дан какой-то физический прибор, и пусть $\xi$ -- случайная величина, описывающая результат измерения этим прибором, $\xi \sim P_{\xi}$ ($\xi$ имеет распределение $P_{\xi}$). Например, если прибор -- это счетчик Гейгера, то $\xi$ -- это уровень радиации, им зарегестрированный. Давайте также считать, что на время эксперимента распределение $\xi$ не меняется, и результат измерения прибора не зависит от предыдущих измерений.  Пусть $X_1, \dots, X_n$ -- эти результаты измерения в какие-то моменты времени. На языке теории вероятностей это можно переформулировать так: $X_1, \dots, X_n$ -- \textit{реализации независимых одинаково распределенных случайных величин} $\xi_1, \dots, \xi_n$. 

	Задача состоит в том, чтобы оценить $E\xi$ по этим самым $X_1, \dots, X_n$.
\end{example}

\begin{example}[Регрессионная модель]
	Пусть материальная точка движется по прямой, стартовав из точки $x_0$ с постоянной скоростью, равной $v_0$. Мы их не знаем, и будем считать, что это случайные величины. Пусть $x_1, \dots, x_n$ -- это измеренные нами положения этой материальной точки в моменты времени $t_1, \dots, t_n$ соответственно. Или, по другому, $x_1, \dots, x_n$ -- это реализации случайных величин $\xi_1, \dots, \xi_n$, причем $\xi_i$ отвечает за измеренный нами результат положения точки в момент времени $t_i$. Понятно, что эти случайные величины уже будут зависимы. Дополнительно положим, что \textit{погрешность измерения подчиняется нормальному распределению}. То есть: $\xi_i = x_0 + v_0 \cdot t_i + \varepsilon_i$, где $\varepsilon_i$ -- нормально распределенная случайная величина, отвечающая за ошибку $i$-того измерения.

	Задача заключается в том, чтобы оценить $x_0$ и $v_0$ по этим данным ($x_0, \dots, x_n, t_0, \dots, t_n$)
\end{example}

\begin{example}[Проверка на однородность]
	Пусть $X_1, \dots, X_n$ -- это результаты эксперимента в условиях $A$, а $Y_1, \dots, Y_m$ -- результаты того-же самого эксперимента в условиях $B$. Нужно выяснить, влияют ли эти условия на результат. (Если для сокращения записи отождествить результат эксперимента со случайной величиной, реализацией которой он является, а также считать, что $X_i \sim X$, $Y_i \sim Y$ то можно записать так: $X \stackrel{d}{\sim} Y$?)
\end{example}

\begin{remark}
	Как мы видим, задача матстатистики -- представить оптимальное решение на основе статистических данных. Типичная характерная черта задач -- это довольно большое количество дополнительных ограничений на природу явлений (независимость и одинаковая распределенность результата, нормальное распределение погрешностей и т.д.). Такие ограничения в реальных условиях иногда бывает трудно проверить, поэтому нужно быть крайне внимательным при применении какого-либо результата из матстатистики в реальных задачах. Однако такое требование к внимательности компенсируется тем, что результаты из матстатистики находят широкое применение в экспериментальной физике, машинном обучении, data mining и прочих облостях науки.
\end{remark}

\subsection{Сходимости случайных векторов}

\begin{definition}
	Пусть $\{\xi_n : n \in \mathbb{N}\}$ -- последовательность случайных векторов из $\mathbb{R}^m$. $\xi$ -- случайный вектор из $\mathbb{R}^m$. Говорят что:
	\begin{itemize}
		\item $\xi_n$ сходится к $\xi$ почти наверное (обозначение: $\xi_n \cae \xi$), если :
			$$P(\{\omega : \lim_{n \rightarrow \infty} \xi_n(\omega) = \xi(\omega)\}) = 1$$
		\item $\xi_n$ сходится к $\xi$ по вероятности (обозначение $\xi_n \cp \xi$), если:
			$$\forall \varepsilon > 0 : \lim_{n \rightarrow \infty} P(\{\omega : \|\xi_n(\omega) - \xi(\omega)\| > \varepsilon) = 0$$
		\item $\xi_n$ сходится к $\xi$ по распределению (обозначение $\xi_n \cd \xi$), если:
			$$\forall f \text{ -- ограниченной непрерывной функции $\mathbb{R} \mapsto \mathbb{R}$} : \lim_{n \rightarrow \infty}Ef(\xi_n) = Ef(\xi)$$
	\end{itemize}
\end{definition}

\begin{statement}
	Пусть $\xi_n = (\xi_n^1, \dots, \xi_n^m), \xi = (\xi^1, \dots, \xi^m)$. Тогда:
	\begin{itemize}
		\item $\xi_n \cae \xi \Leftrightarrow \forall j : \xi_n^j \cae \xi^j$
		\item $\xi_n \cp \xi \Leftrightarrow \forall j : \xi_n^j \cp \xi^j$
	\end{itemize}
\end{statement}

\begin{remark}
	Для сходимости по распределению это утверждение не верно
\end{remark}

\subsection{Предельные теоремы}

\begin{theorem}[Закон большых чисел]
	Пусть $\xi_1, \xi_2, \dots$ -- попарно-некоррелированные одинаково распределенные случайные величины, $D\xi_i$ конечна, $S_n = \xi_1 + \dots + \xi_n$. Тогда:
	$$\frac{S_n - ES_n}{n} \cp 0$$, причем $ES_n = n \cdot a$, $a = E\xi_i$.
\end{theorem}

\begin{theorem}[Усиленный закон больших чисел]
	Пусть $\xi_1, \xi_2, \dots$ -- независимые одинаково распределнные случайные величины, $E\xi_i = a$ -- конечно, $S_n = \xi_1 + \dots + \xi_n$. Тогда:
	$$\frac{S_n}{n} \cae a$$
\end{theorem}

\begin{theorem}[Центральная предельная теорема]
	Пусть $\xi_1, \xi_2, \dots$ -- независимые одинаково распределнные случайные величины, $E\xi_i = a$ -- конечно, $0 < D\xi_i = \sigma^2$ -- тоже конечно, $S_n = \xi_1 + \dots + \xi_n$. Тогда:
	$$\sqrt{n}\left(\frac{S_n}{n} - a\right) \cd \mathcal{N}(0, \sigma^2)$$
\end{theorem}

\end{document}

